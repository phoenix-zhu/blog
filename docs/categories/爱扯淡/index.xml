<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>爱扯淡 on dAmN Ooooooops</title>
    <link>https://blog.damnops.com/categories/%E7%88%B1%E6%89%AF%E6%B7%A1/</link>
    <description>Recent content in 爱扯淡 on dAmN Ooooooops</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>dAmNOps.com</copyright>
    <lastBuildDate>Thu, 21 May 2020 15:20:09 +0800</lastBuildDate>
    
	<atom:link href="https://blog.damnops.com/categories/%E7%88%B1%E6%89%AF%E6%B7%A1/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>爱扯淡 - docker build的好实践和坏实践</title>
      <link>https://blog.damnops.com/ichegg-docker-build-practice/</link>
      <pubDate>Thu, 21 May 2020 15:20:09 +0800</pubDate>
      
      <guid>https://blog.damnops.com/ichegg-docker-build-practice/</guid>
      <description>引言 Docker已经妥妥的成为了容器的业界标准，虽然不时的还有一些什么rkt, lxd将会是接下来的潮流之类的预言，但是至今也还未见能挑起大梁的后起之秀出现，我等俗人还是先顺应当前的潮流吧。而build镜像则是如何把docker使用好的占比非常大的一块内容，今天的话题也是始于群里面一个如何能更快的build docker image的问题。
Best Practice 其实我们并没有讨论什么坏实践，更多的是在围绕我们觉得好的实践是什么和疑问来展开的，这次我就不按照讨论的节奏来总结了，直接上汇总的结果了。总体来讲，build镜像的目标就是尽可能的让镜像小并能兼顾高效和安全。
官方的best practice Docker官方有一个best practice的文档，这个里面写了一些非常好的通用的实践，估摸着大部分人应该都看过了，我在这里摘抄一下核心的内容，鉴于文档里面都有详细的说明和例子，我简单的说一下我的理解。
 构建可随时终止的容器(Create ephemeral containers)，这一点咋看起来似乎和build image没有什么关系，但是其实是一个大的宗旨，就是说在build镜像的时候，你要以镜像将来创建出来的容器是可随时终止和替换的为目标，就和12因子应用里面对于进程的定义类似，容器只是业务运行的一个临时栖所，你不应该把有状态或者需要共享和传承的东西放在镜像里面。 使用.dockerignore排除不相干的文件(Exclude with .dockerignore)，docker是一个C/S架构的应用，build这个过程是在S端进行的，所以build的时候C端会把当前目录的文件当作build context传给S端，如果传了很多在build image的过程中用不到的文件，就会有无谓的性能和时间上的损失，所以合理的使用.dockerignore文件排除不相干的文件。 使用多阶段构建(Use multi-stage builds)，这个不多讲，很多的程序是或者业务最终需要的其实是一些编译的产出物，但是编译的过程会需要很多在运行时不会用到的依赖，多阶段构建就是为了解决这个问题的。 只安装必须的文件包(Don’t install unnecessary packages)，这个不解释。 解耦业务(Decouple applications)，这个说白了就是docker设计的核心理念，一个容器应该只有一个进程，现实中可的业务需求真的很难完全做到这个，但是尽量吧。 最小化层数(Minimize the number of layers)，这一点，我个人其实持保留态度，因为他和接下来的使用Cache这个在某种程度上是有冲突的，具体根据情况做取舍吧。 使用Cache(Leverage build cache)，这个作为如何快速的构建镜像的金律，人人都知道，不多说。 使用多行参数并排序(Sort multi-line arguments)，程序员的基础素养，写清晰易读的代码。  我们的best practice 除了官方的之外，我们在平时使用中也有一些适合自己的实践，列在下面供大家参考。
  尽可能使用Alpine版本的基础镜像，这个可以理解，小嘛，但是里面的工具和服务都是定制过的，通用性相对差一些，和其他的流行的版本还是有一些差别的，可能需要你对使用到的工具的参数，服务的配置做一些处理。
  锁死镜像的版本，非精细化的版本tag其实是会随时更新的，比如ruby:2，你也不知道哪天它会从2.1升到2.2了，很可能这个变化就导致了不期望的或者和之前不一致的结果，所以有一个办法就是带上镜像的sha256签名，比如ruby:2@sha256:15083783ce61a90002eb175a0de2c198afb74b49bd87d52d329e2f4a57b21562，这样你永远拿到的都是那个唯一的版本，如果你需要知道某一个tag的最新的sha256，推荐一个小工具 dfresh。不过这个实践你要灵活使用，比如说我的项目需求是即使这个代码库已经没有新的feature开发了，但是还是需要定期的更新语言和依赖到最新的版本，以确保我的代码不是僵尸代码，而且是有最新的安全补丁的，这种情况下，你可能也需要类似于dfresh这样的工具更新基本镜像的实际版本，或者说如果你能有办法知道某一个workable的基础镜像的sha256也是可以的。
  干净的依赖安装，这个可能是很多人都没有关注到一个点，比如说我们使用的是nodejs，大部分人的Dockerfile中相关的部分可能会是下面这样的。
FROMnode:10 COPY . .RUN yarn install这个看起来好像没有什么问题，但是如果你的dockerignore文件如果没有处理好，有可能就会把本机的node_modules在安装之前就一起copy进去了，这样其实你就污染了build环境，同样的代码，别人打出来的包和你的包有可能是不一致的，即使看起来我们也使用了lock文件。推荐的写法是：
FROMnode:10 COPY yarn.lock .RUN yarn installCOPY . .甚至在有必要的时候使用Volume这个黑魔法。</description>
    </item>
    
    <item>
      <title>爱扯淡 - 再说devops</title>
      <link>https://blog.damnops.com/ichegg-talk-about-devops/</link>
      <pubDate>Sat, 18 Apr 2020 14:18:32 +0800</pubDate>
      
      <guid>https://blog.damnops.com/ichegg-talk-about-devops/</guid>
      <description>写在前面 我也不知道为什么发cal的时候把话题起成了“再说devops”（至于为什么写成devops，请参考我的这篇blog《关于devops的拼写》），因为我们之前其实也没有说过这个。但是可能觉得我们其实平时在不停的说devops，所以就内心里面这个是一个再次重提的话题。
什么是devops Wiki上的定义如下，这个也是我们能看到的绝大部分资料上的定义。
DevOps（Development和Operations的组合词）是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。 不过一千个人心中有一千个哈姆雷特，虽然我们都认同了这个定义，但是对于组成这个定义的那些词语的解释却是各自一表。
今天的讨论中刚开始也是这样，有基于概念本身阐述的。
devops是一种打破dev和ops之间边界，把两个角色的工作磨合到一起，从计划制定开始，到需求分析，开发，测试，部署上线。使用一些自动化工具和项目管理实践，提升项目的交付质量和速度。 也有结合自己经历过的devops组织结构模式的变化，提出来自己对于devops深层的本质的理解。
1. 建立统一标准。 2. 屏蔽技术壁垒。 而在这个讨论过程中，就有一些更具体的问题，我们在devops实践过程中碰到的一些做法对不对？比如说：为什么我们能看到devops这个角色或者职位，到底devops是一个工种，他要去负责dev+ops的活，还是一种站在对方的角度思考问题的文化？如果我们不了解对方的专业领域的知识，我们又怎么去理解对方，打破壁垒？这个讨论中小伙伴们都拿出了自己的案例来说明自己的观点。在我看来，如同人类社会发展一样，从原始社会，奴隶社会到封建社会，再到我们今天的资本主义社会和社会主义社会，下一步是共产主义社会。目前我们能看到的这些不同的做法和组织形态，都可以算的上是devops，只不过是成熟度不同所在不同阶段而已。
下面这张图是Jez Humble提出来的devops的5大基石/支柱，也算是在圈内认同度比较高的一个解释框架。
请注意最下面部分那句 “In DevOps, it&amp;rsquo;s always people over process over tools&amp;quot;，所以如同我上面的所述，当我们还知识关注于工具和实施自动化的时候，相对的还处于比较初级的阶段。之后再进一步开始引入精益，建立成熟的流程，就高级了一些。最后上升到关注人文，能够共担责任的时候，就可以称得上完美的devops实践了。hmm~这么说来，倒是更像马斯洛的需求层次理论，我们之后讨论的内容应该更能佐证我的这个观点吧。
怎么才能更好的推动devops 这个是最现实也是最无力的问题，毕竟devops怎么听都是一个很美好的东西，但是为什么我们在推行devops的时候还是遇到了各种各样的阻力？
大家用自己的亲身经历总结出来的最有效的方法是：切身的痛点(利益)才是内在驱动力。不论是从上向下的被动模式还是从下往上的主动模式，一定是驱动的人从中看到了这个事情能给他带来所谓的“价值”，也就是我前面括号里面赤果果的翻译：利益。
至于什么是“价值”，讨论到最后终是变成了最正确的废话：对方真正看中的东西。不同的人和角色在不同的时段对于看重的东西是不一样的，了解他们在当前关注的能给他带来的“价值”的点，然后有对应的方案就比较好推动了。
而另外一个切入点，就是有足够的权威，当对方足够信任你或者你有足够的威信的时候，你说的就是对的，即使它是错的。如果你不幸搞错了，可能实施的人觉得是自己哪里没做对，然后失败了。现实就是这么冰冷，无情而残酷。
国内外devops实施的差别 这个是很有趣的一件事情。在国内做devops，最终十有八九就是以采用了一些devops工具或者开发了一个devops平台来宣告成功。而在国外，你要和行内人士说devops平台，他肯定不能理解，为什么有了一个平台就算是落地devops了？这个看起来更多的是我们主流的发展思路不同导致的，如同我国在国际上的优势领域多是效率驱动型的一样，我们在devops上也是以提升效率为主，很少讨论人文层面的比较虚无的东西。而国外很多的时候是反着来，所以也就如小伙伴笑称的：国内关注结果，国外享受过程。
相关资料  关于devops的拼写 Wiki上的devops的定义 devops组织结构模式 Jez Humble devops的5大基石/支柱 马斯洛的需求层次理论 我国在国际上的优势领域  </description>
    </item>
    
    <item>
      <title>爱扯淡 - 监控报警的那点事</title>
      <link>https://blog.damnops.com/ichegg-about-monitor-and-alert/</link>
      <pubDate>Tue, 24 Mar 2020 11:30:33 +0800</pubDate>
      
      <guid>https://blog.damnops.com/ichegg-about-monitor-and-alert/</guid>
      <description>引子 想和大家聊这个话题是因为我最近在帮客户梳理他自己的关于监控的一些想法，虽然我自己算是有一套体系，但是客户想站在更高的一个抽象的层面去推销他自己的理念，觉得我的那个太过于技术化，于是乎，我就想听听大家关于这一方面的见解，然后就有了今天的这个话题。
监控的原则 我自己关于监控的原则改变是从13年接触云服务开始，基于基础设施和平台变成了服务带来的关于架构设计思路变化导致的监控方式的连锁反应形成的。毕竟以前ops是要管物理设备的，但是当这些东西变成服务的时候，我们就不需要再去操心这些东西了，这也是我觉得devops理念在那之后才能有快速发展的基础。所以当我们的基础设施和平台具有自动伸缩的能力，虚拟化成为成熟的服务，以及随着容器化和编排的进一步成熟，牲口模式也成为架构设计所采用的通用原则，我们的监控的理念也进一步升级，更多的是去站在业务的角度关注可用性和性能，典型的就是Google SRE实践里面推行的，而不再关注具体资源的状态和性能。但是我们并不是说完全不要这些了，我们还是会尽可能的去监控和记录我们能需要的一切东西，毕竟这些在发生问题时定位根因是非常有用的。
但是中间有同学提到了，我们的一些项目还是需要去管理物理设备的，对于这种东西，我们的设计分层原则基本上就是经典的IPS(A)分层，I(nfrastructure)层面更多的关注设备的存活状态，性能，容量等，P(latform)层去看系统和基础服务本身的状态，是需要关注的最多的一个地方，除了系统和服务本身的存活状态，性能，容量等之外还需要关注他们高可用的状态，其本身对于资源的利用情况等等，以确保服务在稳定的基础上最大化的利用资源，并能为可伸缩提供支撑，Software/Service/Application这个基本上就是我上面说的关注点，但是没有devops之前，ops在这一块更多的是关心业务的存活性，而且还是基于具体资源的业务存活性，很少会整体去评估业务的状态。至于业务方面的东西，就看产品和开发的博弈结果了。但是随着devops的成熟，使用业务相关指标已经成为团队的共识了。
监控我们常用的工具有：Zabbix, Nagios, Prometheus, NewRelic, Cloudwatch, ELK等。
报警通知和响应 当拥有一个完备的监控系统的时候，我们还需要报警通知和响应机制来把最后这一步给完善了，毕竟，我们要确保服务尽可能的高可用，还是需要在发生无法自我修复问题的时候及时的感知到并作出响应的。这个包含两个内容：1. 通知值守人员；2. 接到消息之后如何应对。
报警通知是一个非常恼人的话题，它又包含多个小的点。第一，噪音消除，毕竟我们很大程度上会监控非常多的东西，对于一个资源或者服务我们在不同的层面监控了不同的内容，或者使用多个工具做交叉监控以避免监控工具的单点故障。所以当某个东西有问题的时候，所有的对应的监控都会发生状态变化。如果不经过滤的把消息全发出去，可想而知会发生什么，所以如何消除报警噪音是一个永恒的话题，一般会采用尽可能的合并同类信息以及基于更低层的监控状态抑制的依赖失败的方式来消除不必要的噪音。第二，就是什么情况需要报警，这个要基于意义来出发，我们不想把有限的精力投入到意义不大的事情上去。我个人的原则是：如果这个问题如果不处理就会影响到业务可用性了，不管是外部的SLA还是内部使用的SLO，那就是需要报警的。如果这个事情并不是很紧急，比如说我的某个系统发生了高可用的主备切换，老的主设备有可能发生了故障，但是这个问题并不会直接影响到我的业务的性能和可用性，那我可能采用其他的渠道来感知，而不是报警的方式。所以，我的理念是：一旦接到报警，必须放下手头的事情，立即响应。因为如果说不是所有的报警是需要马上投入解决的内容，那有可能会让值守的人员造成懈怠，错过夹杂在连续的不用立即响应的报警中的需要立即响应的报警信息，这个比较绕，多读两遍吧。当然，你可以把一些实际中并非需要马上响应的事情在你在实践中强制值守人员马上响应，形成习惯。第三，报警信息的具体内容，报警内容携带足够多且明确的内容也是我们一直追求的，如果我们收到了一条类似于Critical: Minimum HealthCheckStatus LessThanThreshold 1.0, Triggered by: Amazon Cloudwatch这样的报警，我估计绝大部分值守人员也是一头雾水，不知道到底发生了什么事情，等到他登陆了AWS，从Cloudwatch里面找到一些有用的信息的时候，估摸也差不多浪费了3，5分钟了，起码这个月4个9的目标是没戏了。关于怎么结合业务和你的通知工具发送内容只能靠大家伙自己摸索了，毕竟这个并没有什么通用的标准，但是不管怎么样，确保值守人员能在看到消息的时候尽可能的获取到最多的有效信息是关键。有小伙伴在这里提到了某个项目采用了唯一错误编码的方式，可以用这个代码追踪到具体出错的代码所在的文件和行数，虽然他没有办法提供太多的架构设计和实现上的细节，但是听起来也挺高大上的。
接到消息如何应对就是我们常说的IRP(Incident Response Plan)，这个东西也是各家有各家的玩法，毕竟做响应的团队组成的角色都是可能有很大的差异的，有一些只有单纯的ops，或者会加入dev，有一些可能会把业务人员也纳入进来，怎么让其他的成员了解面对的问题并加入响应是重点。另外这个Plan里面也需要覆盖如何升级(Escalation)这一块，毕竟有些问题可能不单纯的是技术问题，比如隐私，商业数据丢失或者泄漏等，需要更高层面的角色根据当地的法律来做应对措施的，简而言之，怎么有效的组织有相应能力的人员来解决实际的问题是核心。
报警通知我们用的工具有：Pagerduty，常用的IM工具。
一个美好的监控系统 虽然监控系统里面很多的时候会包含一个展示台，但是这个不是我们今天要讨论的内容，所以就没有展开。但是轩在聊的时候描述了一个非常美好的画面，就是我们在接收到报警之后，能有一个地方，可以看到这个报警或者某个请求所有的相关的信息的，最好是可以图形化的，从这个请求进入我们系统的第一个地方比如说负载均衡器或者CDN开始，到最终这个请求出现问题或者处理完成，这中间不但有这个业务的调用链，也有对应的当时具体处理这个请求的资源的相关状态。抛开这个系统的复杂度不谈，只是所需要的基础信息的标准制定和收集就是一个很大的挑战，毕竟就目前我们碰到的现实情况，都是业务为导向，保证交付效率才是王道，除非真的要到了一定的体量，而且这一块的欠缺影响到整体商业推广和问题溯源了，需要高层次的角色来在整个公司内推动这个事情，否则，所有的一切都是一个美好的愿望而已。但就如Facebook，AWS，阿里等这些行业领头羊，我所了解到他们也只是部分实现，并没有完成这样一个完美的支撑系统，从我有限的使用AWS和阿里的技术支持的结果来看，AWS至少在信息收集和溯源上还是比较成熟了，阿里么，我只能遗憾的说，还处于散兵游勇状态。但是我觉得总有一天，这个东西一定会有，并且成为大型系统的监控工具基础组件。
OFC的野望 OFC是Opportunities For Consistency的缩写，这个是我们一个客户的实践，旨在提炼出一些好的可通用的实践，推行到所有的项目组里面，这样的话，不同的人员转换项目的时候，在相应的方面有统一的上下文，降低一些学习成本。我们之后也会考虑把我们各个项目的一些好的实践可以抽离成一些OFC并推行开来，目前我们已经有的OFC文档里面包含了一篇关于监控的，所以就顺便提了下这个，如果各位小伙伴们项目中有自己觉得不错的可以推广的类似的实践，请联系我们哦。
关于智能监控 这个话题其实其中一位小伙伴想听的内容，但是很可惜，我们参与讨论的人都只有有限的知识储备，所以并没有说太多。虽然我了解到BATJ有一些这方面的实践，但是看到的都是零星的介绍，并没有具体的技术类的资料。不过从大部分可见的信息和我们的需求来看，主要还是结合历史数据来做趋势预测和异常分析比较多。其中有小伙伴提到Nagios新版本有相关的功能，我简单的搜索一下，只找到这个How To Use Capacity Planning的文档。我比较熟悉的AWS Cloudwatch也有提供一个Anomaly Detection的功能。总体来看，这一块如果自己做，是需要结合一些统计算法和ML算法来实现的，对于专业知识的依赖度还是比较高。但是好的一点是，平台和工具里面开始提供类似的功能，这个大大的降低了我们的门槛，如果你们有这方面的资料或者经验，也可以留言分享给大家。
相关资料  牲口模式 How To Use Capacity Planning Anomaly Detection  </description>
    </item>
    
    <item>
      <title>关于爱扯淡的事情</title>
      <link>https://blog.damnops.com/about-ichegg/</link>
      <pubDate>Tue, 24 Mar 2020 11:13:33 +0800</pubDate>
      
      <guid>https://blog.damnops.com/about-ichegg/</guid>
      <description>很久以前，其实也没有很久，大概也就4年前吧，我和小宝就一直想着做一个专门扯淡的活动，成立了一个“爱扯淡”的民间组织，而且还注册了一个域名ichegg.org用来准备输出我们的一些成果的，但是后来搞了两次活动，之后因为一些原因就偃旗息鼓了，域名也被小宝用来当个人博客了。多少次午夜梦回，我还是会时不时的想起这个伟大的梦想，想去把它做下去，今天这个就当是我再次踏上扯淡的征程的开始吧，非常感谢今天来参加扯淡的各位，也希望以后有更多的人参与到这个伟大的活动中来。
BTW, 这个主题相关的内容并不是成熟思考过整理出来的有逻辑结构的内容，只是就我们讨论的内容做的一些简单的归纳整理，毕竟轩还是一再强调我们所做的事情是需要输出的，如果没有输出，可能意义真趋近于零了，所以，花点时间写一下，聊胜于无吧。也希望你们看了的人能从中真的学到点什么，那就更好了。</description>
    </item>
    
  </channel>
</rss>